---
run_name: [RUN_NAME]
master_port: "12402"
load_model_path: [Path or None]

log_config:
  use_tensorboard: True
  tensorboard_log: [Path]
  training_log: [Path]
  evaluation_log: [Path]

model_config:
  context_warmup: 512
  max_position_loss_weighting: 128000
  policy_loss_type: CrossEntropy

  vocab_size: 516 # nobs + nagent + ntag + value_num + 10
  nobs: 100
  nagent: 100
  ntag: 6
  default_tag: 5
  value_num: 300
  resolution: 0.1

  word_embeddings:
      model_type: MLP
      input_type: Discrete
      input_size: 516
      hidden_size: 1024
      dropout: 0.0
  output_layers:
      model_type: MLP
      output_type: Discrete
      input_size: 1024
      hidden_size: 516
      layer_norm: True
      residual_connect: False
      dropout: 0.0

  causal_block_bak_1: # change to causal_block if use this block
      model_type: TRANSFORMER
      num_layers: 6
      hidden_size: 1024
      nhead: 8
      inner_hidden_size: 2048
      dropout: 0.10
      context_window: -1
      checkpoints_density: -1
      position_encoding_size: 12000
      use_layer_norm: True
      use_blockrecurrence: True
      memory_length: 3000
      memory_type: KV
      is_frozen: False

  causal_block_bak_2:
      model_type: GSA # GLA
      num_layers: 18
      hidden_size: 1024
      inner_hidden_size: 2048
      dropout: 0.10
      nhead: 8
      use_layer_norm: True
      gate_bound: 22
      use_blockrecurrence: True
      checkpoints_density: -1
      memory_type: MEM
      memory_length: 0 
      is_frozen: False
      is_generate: False

  causal_block_bak_3:
      model_type: RWKV6
      num_layers: 12
      hidden_size: 1024
      inner_hidden_size: 2048
      dropout: 0.10
      nhead: 16
      expand_k: 1
      expand_v: 2
      hidden_ratio: 3.5
      use_layer_norm: True
      use_blockrecurrence: True
      checkpoints_density: -1
      gate_bound: 12
      memory_type: MEM
      memory_length: 0
      is_frozen: False

  causal_block:
      model_type: RWKV7
      num_layers: 12
      hidden_size: 1024
      inner_hidden_size: 2048
      dropout: 0.10
      nhead: 8
      use_layer_norm: True
      use_blockrecurrence: True
      checkpoints_density: -1
      memory_type: MEM
      memory_length: 0
      is_frozen: False

  causal_block_bak_5:
      model_type: DELTANET
      num_layers: 18
      hidden_size: 1024
      inner_hidden_size: 2048
      dropout: 0.10
      nhead: 8
      expand_v: 1 # default 2
      use_layer_norm: True
      use_blockrecurrence: True
      checkpoints_density: -1
      memory_type: MEM
      memory_length: 0
      is_frozen: False
      is_generate: False

  causal_block_bak_6:
      model_type: Mamba
      num_layers: 12
      hidden_size: 1024
      inner_hidden_size: 2048
      expand: 2
      d_conv: 4
      d_state: 16
      dropout: 0.10
      position_encoding_size: 12000
      use_layer_norm: True
      use_blockrecurrence: True
      checkpoints_density: -1
      memory_length: 0
      memory_type: MEM
      is_frozen: False

  causal_block_bak_7:
      model_type: Mamba2
      num_layers: 12
      hidden_size: 1024
      inner_hidden_size: 2048
      dropout: 0.10
      nhead: 8
      use_segment_input: True
      use_layer_norm: True
      use_blockrecurrence: True
      checkpoints_density: -1
      memory_length: 0
      memory_type: MEM
      is_frozen: False

train_config:
    max_epochs: 20
    batch_size: 12

    seq_len: 16000
    seg_len: 4000

    manual_sync: True

    lr: 2.0e-4
    lr_decay_interval: 2000
    lr_start_step: 8000

    data_path: [Path]
    save_model_path: [Path]
    max_save_iterations: 1000

    state_dropout: 0.0
    reward_dropout: 0.0

    lossweight_policymodel: 0.75
    lossweight_worldmodel_states: 0.15
    lossweight_worldmodel_actions: 0.05
    lossweight_worldmodel_rewards: 0.05
    lossweight_entropy: 0.0
    lossweight_l2: 0.0

    use_amp: False
    use_scaler: False

test_config:
    batch_size: 16
    data_path: [Path]
    output: "./offline_eval/"
    seq_len: 16000
    seg_len: 4000

